{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ferramentas de Análise de Paralelismo - Intel Advisor\n",
    "### Importante : \n",
    "Para execução deste material, é preciso a instalação do [_HPC Intel Toolkit_](https://www.intel.com/content/www/us/en/developer/tools/oneapi/hpc-toolkit-download.html) ou pelo uso da __Intel Devcloud__. Neste jupyter, faremos a demonstração e explicação do roofline por meio de dois exemplos retirados [deste repositorio](https://github.com/oneapi-src/oneAPI-samples):\n",
    "- Mandelbrot\n",
    "- DiscreteCosineTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oque é Roofline ? \n",
    "Roofline é uma representação visual do desempenho do algoritmo em relação ao hardware no qual é executado, oque permite uma análise visual de largura de banda de memória e picos computacionais. O intel Advisor é uma das ferramentas que mede e plota este tipo de gráfico automatizadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos para GPU's \n",
    "Para realizar uma implementação em GPU, é necessario gráficos integrados - de Geração 9 ou 11 - e a transmissao destes dados deve ser efetuada por meio das linguagens de programação _OpenMP, SYCL, DPC++_ ou _OpenCL_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como é o gráfico funciona, na prática? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo abaixo, temos a apresentação de um gráfico de Roofline. Ele é composto principalmente por duas linhas que são os limitantes do hardware em questão, sendo um limitante de Largura de Banda e outro Limitante de Intensidade Operacional. Vamos abordar cada um: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import IFrame\n",
    "os.system(' Terminal de execucao :/bin/echo $(whoami)\\n Analise de Roofline -- roofline.html')\n",
    "IFrame(src='assets/roofline.html', width=1024, height=769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Largura de Memória(Bandwidth):`\n",
    "Temos a representação de _bandwidth_ como a taxa máxima de transferência de dados entre Memória e CPU/GPU esta unidade de transferência de dados é importante para algoritmos em paralelos, justamente porque um dos gargalos que podemos ter em nossos algoritmos é a memória. Esta linha é representada pela linha diagonal principal.\n",
    "\n",
    "\n",
    "- `Intensidade Operacional(I.O):`\n",
    "Apresenta a quantidade de operações artiméticas por byte transferido. Ou seja, apresenta o quanto o processador está \"ocupado\" realizando operações e sua intensidade de acordo com o total de dados recebidos. Vale ressaltar que sua métrica é apresentada pela razão de operações máximas de ponto flutuante(FLOPS) por byte recebido. Esta medida é representa pela linha horizontal.\n",
    "\n",
    "\n",
    "Note que temos mais de uma linha que representa a `largura de banda` e `Intensidade Operacional`. Isso porque , em um mesmo hardware, temos diferentes modos de acesso à memória(Acesso a Memória RAM, cache L1, L2, L3), bem como operações que possuem tamanhos distintos (sizeof float = 32 bits, sizeof double = 64, etc..). Em resumo, temos que levar em conta o tipo de dado que estamos utilizando na nossa operação para determinarmos qual topo teórico será levado em consideração. \n",
    "\n",
    "<img src='assets/r2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gerando Rooflines com exemplos da OneAPI\n",
    "Neste notebook, escolhemos os seguintes exemplos do repositório da oneAPI: \n",
    "- Exemplo 01: Discrete Cossine Transformation (DCT)\n",
    "- Exemplo 02: Sparse Matrix Multiplicação \n",
    "\n",
    "Abordaremos as nuances de cada algoritmo abaixo. Siga as instruções em cada célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile DiscreteCosineTransform/src/CMakeLists.txt\n",
    "# precisamos modificar o CMAkeLists para adicionar um novo target: \"run-profile\"\n",
    "\n",
    "if(PERF_NUM)\n",
    "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g -fsycl -std=c++17 -D PERF_NUM\")\n",
    "message (STATUS \"target will be built for performance tabulation\")\n",
    "else()\n",
    "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsycl -std=c++17\")\n",
    "endif()\n",
    "set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS}\")\n",
    "add_executable (dct DCT.cpp)\n",
    "target_link_libraries(dct OpenCL sycl)\n",
    "file(COPY ../res/willyriver.bmp DESTINATION .)\n",
    "add_custom_target (run ./dct willyriver.bmp willyriver_processed.bmp)\n",
    "\n",
    "add_custom_target(run-profile\n",
    "  COMMAND advisor --collect=roofline --project-dir=./adv --  ./dct willyriver.bmp willyriver_processed.bmp\n",
    "  COMMAND advisor --report=roofline --project-dir=./adv --report-output=./../../../dct_roofline.html\n",
    "  DEPENDS dct\n",
    "  COMMENT \"Running Intel Advisor on dct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile DiscreteCosineTransform/build_run.sh\n",
    "\n",
    "source /opt/intel/inteloneapi/setvars.sh > /dev/null 2>&1s\n",
    "# Advisor env-variables\n",
    "source /opt/intel/inteloneapi/advisor/2023.0.0/advisor-vars.sh\n",
    "source /opt/intel/inteloneapi/advisor/2023.0.0/advixe-vars.sh\n",
    "\n",
    "#Build by CMAKE\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make\n",
    "\n",
    "make run-profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute esta célula para submeter o Exemplo 01.\n",
    "!cd DiscreteCosineTransform && chmod +x build_run.sh && ./build_run.sh;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mandelbrot/src/CMakeLists.txt\n",
    "# precisamos modificar o CMAkeLists para adicionar um novo target: \"run-profile\"\n",
    "\n",
    "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g -std=c++17 -fsycl\")\n",
    "set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS}\")\n",
    "\n",
    "add_executable(mandelbrot main.cpp)\n",
    "target_link_libraries(mandelbrot OpenCL sycl)\n",
    "add_custom_target(run ./mandelbrot)\n",
    "\n",
    "add_executable(mandelbrot_usm main.cpp)\n",
    "target_compile_definitions(mandelbrot_usm PRIVATE MANDELBROT_USM)\n",
    "target_link_libraries(mandelbrot_usm OpenCL sycl)\n",
    "add_custom_target(run_usm ./mandelbrot_usm)\n",
    "\n",
    "add_custom_target(run-profile\n",
    "  COMMAND advisor --collect=roofline --flop --project-dir=./adv -- ./mandelbrot_usm\n",
    "  # direciona o arquivo para a pasta SYCL                \n",
    "  COMMAND advisor --report=roofline --project-dir=./adv --report-output=./../../../mandel_roofline.html\n",
    "  DEPENDS mandelbrot_usm\n",
    "  COMMENT \"Running Intel Advisor on MandelBrot_USM\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mandelbrot/build_run.sh\n",
    "\n",
    "source /opt/intel/inteloneapi/setvars.sh > /dev/null 2>&1s\n",
    "# Advisor ebuild_runriables\n",
    "source /opt/intel/inteloneapi/advisor/2023.0.0/advisor-vars.sh\n",
    "source /opt/intel/inteloneapi/advisor/2023.0.0/advixe-vars.sh\n",
    "\n",
    "#Build by CMAKE\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make\n",
    "\n",
    "make run-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute esta célula para submeter o build do Exemplo 02.\n",
    "!cd mandelbrot && chmod +x build_run.sh && ./build_run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a execução das células acima, você notará a criação de dois arquivos na pasta principal :\n",
    "- dct_roofline.html \n",
    "- mandel_roofline.html \n",
    "\n",
    "Estes arquivos podem ser visualizados aqui mesmo, nas células logo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impressao Roofline de dct\n",
    "from IPython.display import IFrame\n",
    "IFrame('dct_roofline.html', width='100%', height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impressao Roofline de MandelBrot\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='mandel_roofline.html', width='100%', height=769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faça voce mesmo !\n",
    "Agora é a sua vez, faça o upload de algum dos exemplos do [Repositório INTEL](https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL) e faça uma breve análise do resultado obtido de acordo com o caso selecionado !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
