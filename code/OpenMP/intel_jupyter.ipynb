{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao oneAPI e OpenMP* Offload com C/C++"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-requisitos\n",
    "Este curso pressupõe conhecimento geral de OpenMP para CPUs. Se você é novo no OpenMP, abaixo estão alguns ótimos recursos para você começar.\n",
    "* [Curso Básico de OpenMP](https://www.youtube.com/watch?v=nE-xN4Bf8XI&list=PLLX-Q6B8xqZ8n8bwjGdzBJ25X2utwnoEG)\n",
    "* [Especificação OpenMP (para versão 5.0)](https://www.openmp.org/wp-content/uploads/OpenMP-API-Specification-5.0.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral do modelo de software oneAPI\n",
    "O modelo de software oneAPI fornece um portfólio abrangente e unificado de ferramentas de desenvolvedor que podem ser usados com ênfase no hardware, incluindo uma variedade de bibliotecas de desempenho, abrangendo vários tipos de trabalhos. As bibliotecas incluem funções codificadas de forma personalizada para cada arquitetura de destino, de modo que a mesma\n",
    "chamada de função oferece desempenho otimizado em arquiteturas suportadas. A iniciativa oneAPI é baseada em __padrões da indústria e especificações abertas__ e é interoperável com os modelos de programação HPC existentes.\n",
    "\n",
    "<img src=\"img/oneapi2.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluxo de trabalho de nó único HPC com oneAPI\n",
    "O código acelerado pode ser escrito no estilo kernel (SYCL) ou __directive-based__ (OpenMP). Os desenvolvedores __CUDA*__ podem usar a __Intel® DPC++ Compatibility tool__ para realizar uma migração única de __CUDA*__ para __SYCL__. Os aplicativos __Fortran__ e C existentes podem usar construções de descarregamento do OpenMP __offload__. Os aplicativos __C++__ existentes podem escolher o estilo __Kernel__ ou a __opção de estilo baseado em diretiva__ e os aplicativos __OpenCL__ existentes podem permanecer na linguagem OpenCL ou migrar para SYCL.\n",
    "\n",
    "__Intel® Advisor__ é recomendado para __Otimizar__ o design para __vetorização e memória__ (CPU e GPU) e __Identificar__ loops candidatos a __offload__ e projetar o __desempenho nos aceleradores de destino.__\n",
    "\n",
    "A figura abaixo mostra a abordagem recomendada de diferentes pontos de partida para desenvolvedores de HPC:\n",
    "\n",
    "<img src=\"img/workflow.png\">\n",
    "\n",
    "## OpenMP x SYCL\n",
    "Ambos, OpenMP e SYCL, são padrões abertos que podem ser usados para acelerar algoritmos em GPUs. Como mostra o diagrama de fluxo de trabalho, o oneAPI oferece suporte a ambas as metodologias e você deve conseguir obter um desempenho otimizado semelhante com qualquer uma das opções. A decisão entre as duas opções provavelmente depende dos requisitos do fluxo de trabalho e da facilidade de portabilidade. Ao migrar de projetos __CUDA__ ou __OpenCL__ existentes, o SYCL provavelmente faria mais sentido. Ao migrar de aplicativos C/Fortran existentes com __OpenMP__, o descarregamento do OpenMP seria a alternativa mais fácil.\n",
    "\n",
    "## Descarregamento do OpenMP\n",
    "Construções **OpenMP Offload** são um conjunto de diretivas para C++ e Fortran introduzidas no OpenMP 4.0 e aprimoradas ainda mais em versões posteriores que permitem aos desenvolvedores descarregar dados e execução para aceleradores de destino, como GPUs. O descarregamento do OpenMP é suportado no Intel® oneAPI HPC Toolkit com o Intel® C++ Compiler e o Intel® Fortran Compiler."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exercício Simples\n",
    "Este exercício apresenta o OpenMP __Offload__ ao desenvolvedor por meio de um pequeno código simples. Além disso, apresenta ao desenvolvedor o ambiente de notebook Jupyter para edição e salvamento de código; e para executar e enviar programas para o Intel® oneAPI DevCloud.\n",
    "\n",
    "Começamos com um programa que inclui construções OpenMP básicas, incluindo *parallel* e *for*. Em seguida, adicionaremos a diretiva *target* para descarregar parte do programa no dispositivo GPU.\n",
    "\n",
    "Este programa simples percorre todos os elementos da matriz de dados e os multiplica por 2.\n",
    "\n",
    "### Editando o código simple.cpp\n",
    "A célula Jupyter abaixo com o plano de fundo cinza pode ser editada no local e salva.\n",
    "\n",
    "A primeira linha da célula contém o comando **%%writefile 'simple.cpp'** Isso diz à célula de entrada para salvar o conteúdo da célula no nome do arquivo 'simple.cpp' À medida que você edita a célula e a executa , ele salvará suas alterações nesse arquivo.\n",
    "O código abaixo mostra o código OpenMP simples. Inspecione o código, não há modificações necessárias:\n",
    "1. Inspecione a célula de código abaixo e clique em executar ▶ para salvar o código no arquivo\n",
    "2. Em seguida, execute ▶ a célula na seção __Build and Run__ abaixo do código para compilar e executar o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/simple.cpp\n",
    "\n",
    "#include <omp.h>\n",
    "#include <iostream>\n",
    "\n",
    "constexpr int N = 16;\n",
    "int main() {\n",
    "  int is_cpu;\n",
    "  int *data = static_cast<int *>(malloc(N * sizeof(int)));\n",
    "\n",
    "  // Initialization\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  {\n",
    "    is_cpu = omp_is_initial_device();\n",
    "\n",
    "    // Use OpenMP to Parallelize Algorithm\n",
    "#pragma omp parallel for\n",
    "    for (int i = 0; i < N; i++) {\n",
    "      data[i] *= 2;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Print Output\n",
    "  std::cout << \"Running on \" << (is_cpu ? \"CPU\" : \"GPU\") << \"\\n\";\n",
    "  for (int i = 0; i < N; i++) std::cout << data[i] << \"\\n\";\n",
    "\n",
    "  free(data);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Retirar diagnosticos clang++\n",
    "FileBaseName = \"simple\"\n",
    "\n",
    "cc_flags = \"clang++ -w -stdlib=libc++ \"\n",
    "omp_flags = \"-fopenmp -fopenmp-cuda-mode -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_70\"\n",
    "FilePath = \"lab/\"\n",
    "BinPath = \"bin/\"\n",
    "FileName = FileBaseName + \".cpp\"\n",
    "\n",
    "!clang++ -g -v -stdlib=libc++ -Wall $omp_flags $FilePath$FileName -o $BinPath$FileBaseName\n",
    "!./$BinPath$FileBaseName"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diretiva `target`\n",
    "A construção `omp target` transfere o controle e os dados do host para o dispositivo. A transferência de controle é sequencial e síncrona. Em um ambiente de vários dispositivos, a cláusula _device_ pode ser opcionalmente usada para denotar um dispositivo específico. Cada dispositivo recebe um número inteiro específico da implementação. Cláusulas `map` podem ser usadas para controlar a direção do fluxo de dados. As cláusulas `map` serão discutidas em detalhes no próximo módulo.\n",
    "\n",
    "Exemplo - target:\n",
    "```c\n",
    "...// Código Sequencial do Host\n",
    "\n",
    "#pragma omp target //Região de destino executada no dispositivo\n",
    "{\n",
    "     for (...) {\n",
    "         ...;\n",
    "     }\n",
    "}\n",
    "...// Mais código de host sequencial\n",
    "```\n",
    "Exemplo - device: \n",
    "\n",
    "```c\n",
    "...// Código Sequencial do Host\n",
    "\n",
    "int N_GPU = 1;\n",
    "#pragma omp target device(N_GPU)\n",
    "//Região de destino executada no device selecionado\n",
    "{\n",
    "     for (...) {\n",
    "         ...;\n",
    "     }\n",
    "}\n",
    "...// Mais código de host sequencial\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Definindo o dispositivo de destino para depuração\n",
    "Definir a variável de ambiente `OMP_TARGET_OFFLOAD` especifica em qual código de região de destino do dispositivo deve ser executado. Isso permite que o usuário depure o código de área de destino sem modificações.\n",
    "```shell\n",
    "export OMP_TARGET_OFFLOAD={\"MANDATÓRIO\" | \"DESATIVADO\" | \"PADRÃO\" }\n",
    "```\n",
    "* `MANDATORY`: O código da região de destino em execução em uma GPU ou acelerador.\n",
    "* `DISABLED`: O código da região alvo rodando em uma CPU.\n",
    "* `DEFAULT`: O código da região de destino em execução em uma GPU, se o dispositivo estiver disponível, se não estiver, retornará à CPU.\n",
    "\n",
    "Por padrão, `OMP_TARGET_OFFLOAD` é definido como `DEFAULT`.\n",
    "\n",
    "Por exemplo, executar o seguinte comando antes de um programa OpenMP exigirá que o programa execute o código da região de destino em uma CPU.\n",
    "```shell\n",
    "export OMP_TARGET_OFFLOAD=\"DISABLED\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executando um programa OpenMP com a diretiva Target\n",
    "No exemplo abaixo, adicione a diretiva `#pragma omp target map(from:is_cpu) map(tofrom:data[0:N])` onde indicado para descarregar a execução para a GPU. Usamos as cláusulas map aqui para transferir *dados* de e para a GPU enquanto também copiamos o valor de *is_cpu* de volta para o host para ver se nosso código realmente foi executado na GPU. A cláusula map será discutida em detalhes no próximo módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/simple_target.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <omp.h>\n",
    "\n",
    "constexpr int N = 16;\n",
    "int main() {\n",
    "  int is_cpu = true;\n",
    "  int *data = static_cast<int *>(malloc(N * sizeof(int)));\n",
    "\n",
    "  int num_devices = omp_get_num_devices();\n",
    "  printf(\"Number of available devices %d\\n\", num_devices);\n",
    "\n",
    "\n",
    "  // Initialization\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  // Add the target directive here, including the map clause.\n",
    " #pragma omp target map(from : is_cpu) map(tofrom : data [0:N])\n",
    "  {\n",
    "    is_cpu = omp_is_initial_device();\n",
    "#pragma omp parallel for\n",
    "    for (int i = 0; i < N; i++) {\n",
    "      data[i] *= 2;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Print Output\n",
    "  std::cout << \"Running on \" << (is_cpu ? \"CPU\" : \"GPU\") << \"\\n\";\n",
    "  for (int i = 0; i < N; i++) std::cout << data[i] << \"\\n\";\n",
    "\n",
    "  free(data);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução em GPU Nvidia(Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Retirar diagnosticos clang++\n",
    "FileBaseName = \"simple_target\"\n",
    "\n",
    "cc_flags = \"clang++ -w -stdlib=libc++ -Wswitch-enum\"\n",
    "omp_flags = \"-fopenmp -fopenmp-cuda-mode -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_70\"\n",
    "FilePath = \"lab/\"\n",
    "BinPath = \"bin/\"\n",
    "FileName = FileBaseName + \".cpp\"\n",
    "\n",
    "!clang++ -g -v -stdlib=libc++ -Wall $omp_flags $FilePath$FileName -o $BinPath$FileBaseName\n",
    "!./$BinPath$FileBaseName"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução pelo Compilador Intel(DevCloud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferencias de dados para dispositivos com opemMP\n",
    "\n",
    "## Descarregamento de dados\n",
    "O host e os dispositivos têm espaços de memória separados, portanto, quando partes do código são descarregadas, os dados precisam ser mapeados para o dispositivo de destino para serem acessados dentro da região de destino.\n",
    "\n",
    "Por padrão, as variáveis acessadas dentro da região de destino são tratadas da seguinte forma:\n",
    "\n",
    "|Tipo | Comportamento |\n",
    "|:----:|:----|\n",
    "|Escalares | Tratado como `firstprivate` |\n",
    "|Arrays estáticos | Copiado para o dispositivo na entrada e do dispositivo para o host na saída |\n",
    "|Arrays dinâmicos | Igual ao anterior, o comprimento deve ser especificado |\n",
    "\n",
    "No exemplo a seguir, o compilador identificará todas as variáveis usadas na região de destino (a, x e y) e os dados serão transferidos para o dispositivo com base nas regras acima.\n",
    "\n",
    "```c\n",
    "void saxpy() {\n",
    "     float a, x[ARRAY_SIZE], y[ARRAY_SIZE];\n",
    "     #pragma omp target\n",
    "     // Na entrada da região de destino, a, x e y copiados do host para o dispositivo\n",
    "     for (int i=0; i< ARRAY_SIZE; i++) {\n",
    "         y[i] = a * x[i] + y[i];\n",
    "     }\n",
    "     // Ao sair da região de destino, x e y são copiados de volta para o host,\n",
    "     // mesmo que x não tenha sido alterado.\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cláusula `map`\n",
    "\n",
    "Para eliminar cópias de dados desnecessárias, use a cláusula `map` da diretiva `target` para mapear manualmente as variáveis para o ambiente de dados do dispositivo.\n",
    "```c\n",
    "#pragma omp target map(<tipo de map>: variável)\n",
    "```\n",
    "Os *tipos de map* disponíveis são\n",
    "* `alloc`: Aloca armazenamento para variável no dispositivo de destino, valores não copiados\n",
    "* `to`: Aloca armazenamento no dispositivo de destino e atribui valor **da variável do host original ao dispositivo** na entrada da região de destino\n",
    "* `from`: Aloca armazenamento no dispositivo de destino e atribui valor **do dispositivo à variável do host original** na saída da região de destino\n",
    "* `tofrom`: padrão, união de  `to` e `from`\n",
    "\n",
    "<img src=\"img/mapclause.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício: Usos da diretiva `map`\n",
    "\n",
    "Neste exercício, você adicionará uma cláusula map à operação saxpy ($y=ax+y$). O arquivo de origem principal, main.cpp, foi escrito para você. Ele inclui saxpy_func.cpp que você preencherá e gravará no arquivo neste bloco de notas Jupyter. Se você gostaria de ver o conteúdo de main.cpp, execute a seguinte célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcional,visualização dos dados de main_saxpy.cpp\n",
    "%pycat lab/map_saxpy.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, adicione a cláusula map que mapearia a matriz x para o destino para que ela não fosse copiada de volta desnecessariamente. Além disso, adicione a cláusula `map(from:is_cpu)` para sabermos se o código foi executado na GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/saxpy_func.cpp\n",
    "// #TODO: Adicione uma das diretivas de openMP com uso de map\n",
    "\n",
    "{\n",
    "  is_cpu = omp_is_initial_device();\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    y[i] = a * x[i] + y[i];\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, adicione a cláusula map que mapearia a matriz x para o destino para que ela não fosse copiada de volta desnecessariamente. Além disso, adicione a cláusula `map(from:is_cpu)` para sabermos se o código foi executado na GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilar e executar o código\n",
    "Em seguida, compile e execute o código por meio da célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Retirar diagnosticos clang++\n",
    "FileBaseName = \"main_saxpy\"\n",
    "\n",
    "cc_flags = \"clang++ -w -stdlib=libc++ \"\n",
    "omp_flags = \"-fopenmp -fopenmp-cuda-mode -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_70\"\n",
    "FilePath = \"lab/\"\n",
    "BinPath = \"bin/\"\n",
    "FileName = FileBaseName + \".cpp\"\n",
    "\n",
    "!clang++ -g -v -stdlib=libc++ -Wall $omp_flags $FilePath$FileName -o $BinPath$FileBaseName\n",
    "\n",
    "!./$BinPath$FileBaseName"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificação de comprimento e dados alocados dinamicamente\n",
    "\n",
    "Para arrays alocados dinamicamente, ao usar a construção `target map`, o número de elementos a serem mapeados deve ser explicitamente especificado. Arrays parciais podem ser especificadas.\n",
    "```c\n",
    "#pragma omp target map(to:array[start:length])\n",
    "```\n",
    "No exemplo anterior, x e y são Arrays estáticas, portanto, a especificação do comprimento é opcional. Se desejar, você pode voltar ao exemplo anterior e especificar o tamanho do Array a ser mapeado. Como alternativa, você pode executar a célula a seguir para ver a solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat lab/saxpy_func_solution_length.cpp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Região de dados de destino -- target data\n",
    "Quando há mais de uma região de destino, geralmente é útil criar uma região de **dados** de destino maior que englobe todas as regiões de destino para minimizar a cópia de dados nas regiões de destino. Existem duas maneiras de criar uma região de dados de destino, usando `target data` ou usando `target enter data` e `target exit data`.\n",
    "### Dados de destino\n",
    "A construção `target data` cria um ambiente de dados com escopo e mapeia dados de e para o dispositivo. Ao usar esta construção, os tipos de mapa `alloc`, `to`, `from` e `tofrom` estão disponíveis.\n",
    "\n",
    "Observação: `Target Data` não cria uma região de destino que descarrega a execução. Construções `target` dentro do ambiente de dados são necessárias para realizar isso.\n",
    "```c\n",
    "#pragma omp target data map(tofrom: x)\n",
    "// Ambiente de dados do dispositivo criado, x permanece no dispositivo durante as duas regiões de destino\n",
    "{\n",
    "     #pragma omp target(to: y)\n",
    "     {\n",
    "         // Primeira região alvo\n",
    "     }\n",
    "     host_update(s); //Como nao foi especificado, esta função faz \"s\"\n",
    "     // em host(local)\n",
    "     // y deve ser mapeado em cada região de destino porque está sendo atualizado pelo host\n",
    "     #pragma omp target(to: y)\n",
    "     {\n",
    "         // Segunda região alvo\n",
    "     }\n",
    "}\n",
    "```\n",
    "### Target Enter/Exit Data e Update\n",
    "As construções `target enter/exit data` podem ser usadas para marcar explicitamente o início e o fim do ambiente de dados de destino.\n",
    "\n",
    "Ao usar a construção `target enter data`, apenas os tipos de mapa de `alloc` e `to` estão disponíveis. Ao usar a construção `target exit data`, os tipos de mapa `from`, `release` e `delete` estão disponíveis.\n",
    "\n",
    "A construção `target update` é usada para emitir transferências de dados para ou do ambiente de dispositivo de dados existente.\n",
    "\n",
    "Observação: as construções `target enter/exit/update data` não têm escopo e não descarregam a execução do código. As construções `target` são necessárias entre a entrada e a saída do ambiente de dados para realizar isso.\n",
    "\n",
    "Exemplo:\n",
    "```c\n",
    "#pragma omp target enter data map(to:y) map(alloc: x)\n",
    "\n",
    "#pragma omp target\n",
    "{ //Primeira região de destino, operações do dispositivo em x e y\n",
    "}\n",
    "#pragma omp target update from(y)\n",
    "host_update(s);\n",
    "#pragma omp target update to(y)\n",
    "\n",
    "#pragma omp target\n",
    "{ //2ª região de destino, operações do dispositivo em x e y\n",
    "}\n",
    "#pragma omp target exit date map(from:x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício: região de dados de destino\n",
    "Neste exercício, temos duas regiões-alvo. x e y são matrizes estáticas de tamanho ARRAY_SIZE e são usadas nas regiões de destino. Além disso, o valor de y é atualizado pelo host entre as regiões. Para este programa, *main_data_region.cpp* contém main e inclui *target_data_region.cpp*, que é o arquivo que você substituirá.\n",
    "\n",
    "Crie um ambiente de dados de destino que englobe ambas as regiões de destino, certifique-se de que `x` permaneça no dispositivo em toda a região e certifique-se de que `y` seja atualizado no dispositivo após a chamada do host `init2`. Teste seu código e certifique-se de que a mensagem PASSED seja exibida.\n",
    "\n",
    "Existem duas maneiras de resolver esse problema. Você pode optar por usar `target data` ou `target enter/update/exit data`. A solução é fornecida para ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opcional: Examine main_data_region.cpp se quiser.\n",
    "%pycat lab/main_data_region.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/target_data_region.cpp\n",
    "#TODO: quais atributos devo usar ??\n",
    "\n",
    "\n",
    "#pragma omp target data\n",
    "{\n",
    "#pragma omp target \n",
    "  {\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) x[i] += y[i];\n",
    "  }\n",
    "\n",
    "  init2(y, ARRAY_SIZE);\n",
    "\n",
    "#pragma omp target \n",
    "  {\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) x[i] += y[i];\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilar e executar o código\n",
    "Em seguida, compile e execute o código usando *run.sh*. Se você gostaria de ver o conteúdo de run.sh, execute a seguinte célula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Retirar diagnosticos clang++\n",
    "FileBaseName = \"main_data_region\"\n",
    "\n",
    "cc_flags = \"clang++ -w -stdlib=libc++ \"\n",
    "omp_flags = \"-fopenmp -fopenmp-cuda-mode -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_70\"\n",
    "FilePath = \"lab/\"\n",
    "BinPath = \"bin/\"\n",
    "FileName = FileBaseName + \".cpp\"\n",
    "\n",
    "!clang++ -g -v -stdlib=libc++ -Wall $omp_flags $FilePath$FileName -o $BinPath$FileBaseName\n",
    "\n",
    "!./$BinPath$FileBaseName"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta(s) para o exercício\n",
    "\n",
    "__(Vale a pena avaliar os diferentes tipos de soluções)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat lab/target_data_region_solution.cpp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento de Variáveis Globais para o Dispositivo\n",
    "Com o OpenMP, você também tem a opção de mapear uma variável para o dispositivo durante o programa. Use a diretiva `declare target` para especificar que variáveis e funções são mapeadas para um dispositivo. Aqui está um exemplo.\n",
    "\n",
    "```c\n",
    "#pragma omp declare target\n",
    "int a[N]\n",
    "#pragma omp end declare target\n",
    "\n",
    "//Código do host\n",
    "inicial(a);\n",
    "\n",
    "#pragma omp target\n",
    "for (int i=0; i<N; i++) {\n",
    "     resultado[i]=processo(a[i]);\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelismo em dispositivo (C/C++)\n",
    "## Paralelismo de dispositivos\n",
    "Conforme discutimos nos módulos anteriores, a construção `target` do OpenMP transfere o fluxo de controle para o dispositivo de destino. No entanto, a transferência de controle é sequencial e síncrona.\n",
    "\n",
    "No OpenMP, offload e paralelismo são separados, então os programadores precisam criar explicitamente regiões paralelas no dispositivo de destino. Em teoria, construções que criam paralelismo em dispositivos offload podem ser combinadas com qualquer construção OpenMP, mas, na prática, apenas um subconjunto de construções OpenMP é útil para o dispositivo de destino."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura da GPU\n",
    "Antes de mergulhar nas construções de paralelismo OpenMP para dispositivos de destino, vamos primeiro examinar a arquitetura da GPU Intel®.\n",
    "\n",
    "<img src=\"img/GPU_Arch.png\">\n",
    "\n",
    "As GPUs Intel® contêm 1 ou mais fatias. Cada fatia é composta por várias subfatias (também chamadas de núcleos de GPU). Cada subfatia contém vários EUs (provavelmente 8 ou mais), possui sua própria unidade de despacho de encadeamento, cache de instruções, memória local compartilhada e outros recursos. EUs são processadores de computação que dirigem os SIMD ALUs.\n",
    "\n",
    "A tabela a seguir mostra como os conceitos OpenMP de League, Team, Thread e SIMD são mapeados para hardware GPU.\n",
    "\n",
    "|OpenMP | hardware da GPU |\n",
    "|:----:|:----|\n",
    "|SIMD | SIMD (Canal) |\n",
    "|Thread | SIMD Thread mapeado para uma Unidade de Execução(UE) |\n",
    "|Team | Grupo de threads mapeados para uma subfatia |\n",
    "|League | Várias threads mapeadas para uma GPU |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construções OpenMP \"normais\"\n",
    "O descarregamento da GPU OpenMP suporta todas as construções OpenMP \"normais\", como `parallel`, `for`, `barrier`, `sections`, `tasks`, etc. No entanto, nem todas as construções serão úteis para a GPU. Ao usar essas construções, o modelo de encadeamento completo é suportado apenas em uma subfatia, porque não há sincronização entre as subfatias e não há coerência e cerca de memória entre os caches L1 das subfatias.\n",
    "\n",
    "Vamos examinar o seguinte exemplo.\n",
    "```c\n",
    "void saxpy(float a, float* x, float* y, int sz) {\n",
    "     #pragma omp target map(to:x[0:sz]) map(tofrom(y[0:sz])\n",
    "     #pragma omp parallel for simd\n",
    "     for (int i=0; i< sz; i++) {\n",
    "         y[i] = a * x[i] + y[i];\n",
    "     }\n",
    "}\n",
    "```\n",
    "Aqui, usamos o pragma `target` para descarregar a execução para a GPU. Em seguida, usamos `parallel` para criar uma equipe(team) de threads, `for` para distribuir iterações de loop para esses threads e `simd` para solicitar a vetorização de iteração com instruções SIMD. No entanto, devido às restrições mencionadas, apenas um subfatia de GPU é utilizado aqui, portanto, a GPU seria significativamente subutilizada. Em alguns casos, o compilador pode deduzir `team distribute` de `parallel for` e ainda usar toda a GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liga de Equipes(Teams)\n",
    "Para aproveitar várias subfatias, use o pragma `teams` para criar várias threads **mestres** para execução. Quando combinados com o pragma `parallel`, esses threads mestres se tornam uma liga de equipes(teams) de threads. Como não há sincronização entre equipes de threads, as equipes podem ser atribuídas a diferentes subfatias da GPU.\n",
    "\n",
    "<img src=\"img/teams.jpeg\">\n",
    "\n",
    "Ao usar a construção `teams`, o número de equipes criadas é definido pela implementação. No entanto, você pode opcionalmente especificar um limite superior com a cláusula **num_teams**. A cláusula **thread_limit** do pragma `teams` pode ser opcionalmente usada para limitar o número de threads em cada equipe.\n",
    "\n",
    "Exemplo: `#pragma omp teams num_teams(8) thread_limit(16)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartilhamento de trabalho com equipes\n",
    "Depois que uma liga de times é criada por `teams`, use a construção `distribute` para distribuir blocos de iterações de um loop entre os diferentes times da liga. Isso é análogo ao que a construção `for` faz para regiões `paralelas`. O pragma `distribute` está associado a um ninho de loop dentro de uma região de equipes.\n",
    "\n",
    "Para loops aninhados, a cláusula **collapse** pode ser usada para especificar quantos loops estão associados ao pragma `distribute`. Você pode especificar uma cláusula **collapse** com um valor de parâmetro maior que 1 para recolher os loops associados em um loop grande.\n",
    "\n",
    "Você também pode usar a cláusula **dist_schedule** na construção `distribute` para especificar manualmente o tamanho do bloco que é distribuído para os threads principais de cada equipe. Por exemplo, `#pragma omp distribui dist_schedule(static, 512)` criaria pedaços de 512 iterações.\n",
    "\n",
    "### Exemplo com construções combinadas\n",
    "Por conveniência, o OpenMP oferece suporte a construções combinadas para descarregamento do OpenMP. O código abaixo mostra como uma única linha pode abranger todos os pragmas que discutimos.\n",
    "```c\n",
    "void saxpy (float a, float *x, float *y, int sz) {\n",
    "     #pragma equipes de destino omp distribute parallel for simd \\\n",
    "                map(to:x(0:sz)) map(tofrom(y(0:sz))\n",
    "     for (int i=0; i<sz; i++) {\n",
    "         y[i] = a*x[i] + y[i];\n",
    "     }\n",
    "}\n",
    "```\n",
    "Quando essas construções são usadas sem cláusulas adicionais, o número de equipes criadas, o número de encadeamentos criados por equipe e como as iterações de loop são distribuídas são todos definidos pela implementação.\n",
    "O diagrama a seguir detalha os efeitos de cada pragma no exemplo anterior. Aqui, assumimos que há um total de 128 iterações de loop e que 4 times e 4 threads por time são criados pela implementação.\n",
    "\n",
    "1. O pragma `omp target` descarrega a execução para o dispositivo\n",
    "2. O pragma `omp teams` cria vários threads mestres, 4 equipes de threads neste diagrama.\n",
    "3. O pragma `omp distribute` distribui iterações de loop para essas 4 equipes de threads, 32 threads para cada equipe mostrada.\n",
    "4. O pragma `omp parallel` cria um time de threads para cada thread master (team), 4 threads criadas para cada time mostrado.\n",
    "5. O pragma `omp for` distribui as 32 iterações para cada uma das 4 threads.\n",
    "6. O pragma `omp simd` especifica que múltiplas iterações do loop podem ser executadas usando instruções SIMD.\n",
    "\n",
    "<img src=\"img/distribute.jpeg\">\n",
    "\n",
    "OBS: por analogia, existem semelhanças quando trabalhamos com CUDA: `Teams` equivale ao Nro. de blocos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispositivo host e Concorrência\n",
    "\n",
    "Quando uma região de destino é encontrada, uma tarefa de host é gerada, sincronizando a CPU e o dispositivo de destino. O OpenMP usa tarefas para gerenciar a execução e as dependências. Adicione a cláusula `nowait` para que o host não precise esperar que a região de destino seja concluída.\n",
    "\n",
    "```c\n",
    "#pragma omp target nowait\n",
    "```\n",
    "\n",
    "O uso de uma cláusula `nowait` com uma construção `target` permite o descarregamento assíncrono, permitindo que o dispositivo host continue a execução. Uma maneira de sincronizar uma região de destino com o dispositivo host é usando a construção `taskwait`, que aguardará até que todas as tarefas sejam concluídas.\n",
    "\n",
    "No exemplo a seguir, o loop for é transferido para o dispositivo de destino, enquanto o dispositivo host continua a execução e realiza outros trabalhos. Após a conclusão do dispositivo e do host, o dispositivo host continuará a execução.\n",
    "\n",
    "```c\n",
    "#pragma omp target map(to:b,c,d) map(from:a) nowait\n",
    "{\n",
    "     #pragma omp teams distribute parallel for simd\n",
    "     for (i=0; i<500; i++) {\n",
    "         a[i] = b[i] * c + d;\n",
    "     }\n",
    "}\n",
    "\n",
    "#pragma  omp task\n",
    "     outro trabalho();\n",
    "\n",
    "#pragma omp taskwait //Sincronização\n",
    "     a0 = a[0];\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício: Paralelismo de dispositivos OpenMP\n",
    "Neste exercício, praticaremos o uso das construções de compartilhamento de trabalho offload na função saxpy com a qual já trabalhamos nos módulos anteriores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, adicione pragmas OpenMP nos locais indicados para executar as seguintes tarefas.\n",
    "1. Para o loop externo, use uma construção **combinada** para\n",
    "     1. Crie NUM_BLOCKS de threads **master**, use a cláusula *num_teams(NUM_BLOCKS)*\n",
    "     2. Distribua as iterações do loop externo para os threads principais varoius.\n",
    "2. Para o loop interno, use uma construção combinada para\n",
    "     1. Crie uma equipe de encadeamentos para cada encadeamento principal.\n",
    "     2. Distribua as iterações do loop interno para esses threads.\n",
    "     3. Sinal de que várias iterações de loop podem ser executadas simultaneamente com instruções SIMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/saxpy_func_parallel.cpp\n",
    "#pragma omp target map(from: is_cpu) map(from:num_teams) map(to:x[0:ARRAY_SIZE]) map(tofrom:y[0:ARRAY_SIZE])\n",
    "{\n",
    "\n",
    "  // 1. Inclua pragma para criar multiplas threads master --> use num_treads(NUM_BLOCKS)\n",
    "  //    e distribua as iterações dos loop para as threads masters. \n",
    "\n",
    "  for (ib = 0; ib < ARRAY_SIZE; ib += NUM_BLOCKS) {\n",
    "    if (ib == 0) {\n",
    "\n",
    "      //teste de verificação se estamos no Host ou Device..\n",
    "      is_cpu = omp_is_initial_device();\n",
    "      \n",
    "      // obtem o numero de times criados\n",
    "      num_teams = omp_get_num_teams();\n",
    "    }\n",
    "\n",
    "\n",
    "    // 2. Coloque a combinação no pragma para criar o time de threads para\n",
    "    // cada thread master, distribuindo estas threads e vetorizando.\n",
    "\n",
    "    for (i = ib; i < ib + NUM_BLOCKS; i++) {\n",
    "      y[i] = a * x[i] + y[i];\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: devo colocar USM ? no notebook é demonstrado apenas um exemplo,\n",
    "# sem muita explicação prática....\n",
    "\n",
    "#TODO: Retirar diagnosticos clang++\n",
    "FileBaseName = \"main_saxpy_parallel\"\n",
    "\n",
    "cc_flags = \"clang++ -w -stdlib=libc++ \"\n",
    "omp_flags = \"-fopenmp -fopenmp-cuda-mode -fopenmp-targets=nvptx64-nvidia-cuda -Xopenmp-target -march=sm_70\"\n",
    "FilePath = \"lab/\"\n",
    "BinPath = \"bin/\"\n",
    "FileName = FileBaseName + \".cpp\"\n",
    "\n",
    "!clang++ -g -v -stdlib=libc++ -Wall $omp_flags $FilePath$FileName -o $BinPath$FileBaseName\n",
    "\n",
    "!./$BinPath$FileBaseName"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
